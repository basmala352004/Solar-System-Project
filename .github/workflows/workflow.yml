name: solar system workflow

on:
  workflow_dispatch:
  push:
    branches:
      - feature-branch
      - main

env:
  MONGO_URI: "mongodb+srv://supercluster.d83jj.mongodb.net/superData"
  MONGO_USERNAME: ${{ vars.MONGO_USERNAME }}
  MONGO_PASSWORD: ${{ secrets.MONGO_PASSWORD }}
  DOCKERHUB_USERNAME: ${{ vars.DOCKERHUB_USERNAME }}
  DOCKERHUB_PASSWORD: ${{ secrets.DOCKERHUB_PASSWORD }}

jobs:
  unit-test:
    name: unit testing
    strategy:
      matrix:
        node-version: [18,19,20]
        os: [ubuntu-latest, macos-latest, windows-latest]
        exclude:
          - node-version: 18
            os: macos-latest
    runs-on: ${{ matrix.os }}
    steps:
      - name: checkout repo
        uses: actions/checkout@v5

      - name: set up nodesJs version - ${{ matrix.node-version }}
        uses: actions/setup-node@v4.4.0
        with:
          node-version: ${{ matrix.node-version }}
      - name: install dependences
        run: npm install

      - name: unit testing
        id: NodeJs-unit-testing-step
        run: npm test

      - name: Archive test results
        if: steps.NodeJs-unit-testing-step.outcome == 'failure' || steps.NodeJs-unit-testing-step.outcome == 'success'
        uses: actions/upload-artifact@v4.6.2
        with:
          name: 'artifact ${{ matrix.os }}-${{ matrix.node-version }} '
          path: test-results.xml

  code-coverage:
    name: code coverage
    needs: unit-test
    runs-on: ubuntu-latest
    steps:
      - name: checkout
        uses: actions/checkout@v5

      - name: set up nodejs version 18
        uses: actions/setup-node@v4.4.0
        with:
          node-version: 18

      - name: install dep
        run: npm install

      - name: check code coverage
        continue-on-error: true
        run: npm run coverage

      - name: archive coverage results
        uses: actions/upload-artifact@v4.6.2
        with:
          name: code-coverage-Result
          path: coverage
          retention-days: 5

  docker:
    name: containerizations
    permissions:
      contents: read
      packages: write
    runs-on: ubuntu-latest
    steps:
      - name: checkout
        uses: actions/checkout@v5

      - name: docker login
        uses: docker/login-action@v3.5.0
        with:
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      - name: GHCR login
        uses: docker/login-action@v3.5.0
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build Docker file
        uses: docker/build-push-action@v6
        with:
          push: 'false'
          tags: ${{ vars.DOCKERHUB_USERNAME }}/solar-system:latest

      - name: Test Docker image
        run: |
          docker images
          docker run --name solar-system-app -d \
          -p 3000:3000 \
          -e MONGO_URI=$MONGO_URI \
          -e MONGO_USERNAME=$MONGO_USERNAME \
          -e MONGO_PASSWORD=$MONGO_PASSWORD \
          ${{ vars.DOCKERHUB_USERNAME }}/solar-system:latest
          export IP=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' solar-system-app)
          echo $IP
          echo Testing Image URL using wget
          wget -q -O - 127.0.0.1:3000/live | grep  live

      - name: Build Docker file
        uses: docker/build-push-action@v6
        with:
          push: 'true'
          tags: |
            ${{ vars.DOCKERHUB_USERNAME }}/solar-system:latest
            ghcr.io/${{ github.repository_owner }}/solar-system:latest

  terraform:
    name: terraform deployment
    needs: docker
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout
        uses: actions/checkout@v5.0.0

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4.3.1
        with:
          aws-access-key-id: ${{ secrets.aws_access_key_id }}
          aws-secret-access-key: ${{ secrets.aws_secret_access_key }}
          aws-region: us-east-1

      - name: HashiCorp - Set up terraform
        uses: hashicorp/setup-terraform@v3.1.2
        with:
          terraform_version: 'latest' #1.1.7

      - name: terraform init
        run: terraform init
        working-directory: ./terraform2

      - name: terraform plan
        run: terraform plan
        working-directory: ./terraform2

      #- name: terraform apply or destroy.sh
       # run: |
         # if [ "${{ github.event.inputs.destroy }}" - "yes" |; then
          #terraform destroy -auto-approve
         # else
        #   terraform apply -auto-approve
       #   fi
      #  working-directory: ./terraform2

      - name: Terraform apply
        run: terraform apply -auto-approve
        working-directory: ./terraform2

  deploy:
    needs: terraform
    name: deploy to eks
    runs-on: ubuntu-latest

    steps:
      - name: checkout
        uses: actions/checkout@v5

      - name: configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4.3.1
        with:
          aws-access-key-id: ${{ secrets.aws_access_key_id }}
          aws-secret-access-key: ${{ secrets.aws_secret_access_key }}
          aws-region: us-east-1
          #cluster: stage-eks-cluster

      - name: update kubeconfig
        run: |
          aws eks --region us-east-2 update-kubeconfig --name stage-eks-cluster

      - name: Trigger app deployment
        uses: statsig-io/kubectl-via-eksctl@main
        env:
          aws-access-key-id: ${{ secrets.aws_access_key_id }}
          aws-secret-access-key: ${{ secrets.aws_secret_access_key }}
          aws-region: us-east-1
          cluster: stage-eks-cluster

      - name: deploy k8s deployments
        run: |
          kubectl apply -f deployment.yml
          kubectl apply -f service.yml
        working-directory: ./kubernetes2

      - name: Verify Deployment
        run: |
          kubectl get pods  
          kubectl get svc

    deploy-monitoring:
      needs: deploy
      name: deploy to EKS
      runs-on: ubuntu-latest
      env:
        AWS_REGION: us-west-2
        EKS_CLUSTER_NAME: stage-eks-cluster
        GRAFANA_ADMIN_PASSWORD: ${{ secrets.grafana_admin_password }}

      steps:
        - name: checkout config files
          uses: actions/checkout@v5


        - name: Configure AWS Credentials
          uses: aws-actions/configure-aws-credentials@v4.3.1
          with:
            aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws-region: us-west-2

        - name: updat kubeconfig
          run: |
            aws eks --region us-west-2 update-kubeconfig --name stage-eks-cluster

        - name: Trigger app deployment
          uses: statsig-io/kubectl-via-eksctl@main
          env:
            aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            region: us-west-2
            cluster: stage-eks-cluster

#        - name: create monitoring namespace
#          run: kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f

        - name: Add Helm repos
          run: |
            helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
            helm repo add grafana https://grafana.github.io/helm-charts
            helm repo update
        - name: Render values with env
          run: |
            envsubst < values.yml > /tmp/values.rendered.yaml
            echo "Rendered values:"
            tail -n +1 /tmp/values.rendered.yaml
          working-directory: ./kubernetes

        - name: Install/Upgrade kube-prometheus-stack
          run: |
            helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
              --namespace monitoring \
              --values /tmp/values.rendered.yaml \
              --wait --timeout 15m
        - name: Apply ServiceMonitor for my app
          run: |
            kubectl apply -f servicemonitor-splar-system.yaml
          working-directory: ./kubernetes

        - name: Show external endpoints
          run: |
            echo "Waiting for LoadBalancer IPs..."
            kubectl -n monitoring wait --for=condition=available deploy/kube-prometheus-stack-grafana --timeout=10m
            kubectl -n monitoring get svc -o wide
            echo "Grafana URL:"
            kubectl -n monitoring get svc kube-prometheus-stack-grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}{.status.loadBalancer.ingress[0].ip}{"\n"}'
            echo "Prometheus URL:"
            kubectl -n monitoring get svc kube-prometheus-stack-prometheus -o jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}{.status.loadBalancer.ingress[0].ip}{"\n"}'

        - name: Output monitoring namespace YAML
          run: kubectl create namespace monitoring --dry-run=client -o yaml

        - name: Create monitoring namespace
          run: kubectl create namespace monitoring || true
